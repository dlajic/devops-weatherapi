services:
  db:
    image: postgres:15
    container_name: postgres-db
    environment:
      POSTGRES_USER: weather
      POSTGRES_PASSWORD: weather123
      POSTGRES_DB: weatherdb
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U weather -d weatherdb || exit 1"]
      interval: 5s
      timeout: 5s
      retries: 20
      start_period: 10s

  backend:
    build: ./fastapi-service
    container_name: fastapi-backend
    depends_on:
      db:
        condition: service_healthy
    environment:
      - DATABASE_URL=postgresql://weather:weather123@db:5432/weatherdb
    working_dir: /fastapi-service
    # Siehe Schritt 2 unten: Wait-Loop + create_db + uvicorn
    command: >
      bash -lc '
      until pg_isready -h db -p 5432 -U weather -d weatherdb; do
        echo "waiting for db..." && sleep 2
      done;
      python -m app.create_db && uvicorn app.main:app --host 0.0.0.0 --port 8000'
    #ports:
    #  - "8000:8000"
    volumes:
      - ./fastapi-service:/fastapi-service

  airflow-db:
    image: postgres:15
    container_name: airflow-db
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - airflow_postgres_data:/var/lib/postgresql/data

  airflow-scheduler:
    build:
      context: .
      dockerfile: airflow/Dockerfile
    container_name: airflow-scheduler
    depends_on:
      - airflow-db
    environment:
      # Allgemein
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__PARALLELISM=8               # globales Limit
      - AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG=1   # pro DAG nicht eskalieren
      - AIRFLOW__CORE__STORE_SERIALIZED_DAGS=True  # weniger RAM beim Scheduler
      - AIRFLOW__CORE__MIN_SERIALIZED_DAG_UPDATE_INTERVAL=30
      - AIRFLOW__CORE__DAGBAG_IMPORT_TIMEOUT=30

      # Scheduler sparsam halten
      - AIRFLOW__SCHEDULER__PARSING_PROCESSES=1
      - AIRFLOW__SCHEDULER__MAX_THREADS=2
      - AIRFLOW__SCHEDULER__SCHEDULER_HEARTBEAT_SEC=5
      - AIRFLOW__SCHEDULER__MIN_FILE_PROCESS_INTERVAL=30
      - AIRFLOW__SCHEDULER__MAX_DAGRUNS_TO_CREATE_PER_LOOP=2
      - AIRFLOW__SCHEDULER__MAX_TIS_PER_QUERY=8
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-db:5432/airflow
      - AIRFLOW__WEBSERVER__SECRET_KEY=mysupersecret
      - PYTHONPATH=/opt/shared-code
    command: scheduler
    deploy:
      resources:
        limits:
          cpus: '0.75'
          memory: 800M
        reservations:
          cpus: '0.25'
          memory: 256M
    #volumes:
      #- ./airflow/dags:/opt/airflow/dags
      #- ./fastapi-service/app:/opt/shared-code/app


  airflow-webserver:
    build:
      context: .
      dockerfile: airflow/Dockerfile
    container_name: airflow-webserver
    depends_on:
      - airflow-scheduler
    environment:
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__WEBSERVER__WORKERS=1
      - AIRFLOW__WEBSERVER__WORKER_CLASS=sync
      - AIRFLOW__WEBSERVER__WEB_SERVER_WORKER_TIMEOUT=120
      - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=False
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-db:5432/airflow
      - AIRFLOW__WEBSERVER__SECRET_KEY=mysupersecret
      - PYTHONPATH=/opt/shared-code
    command: webserver
    deploy:
      resources:
        limits:
          cpus: '0.75'
          memory: 800M
        reservations:
          cpus: '0.25'
          memory: 256M
    #ports:
    #  - "8080:8080"
    #volumes:
      #- ./airflow/dags:/opt/airflow/dags
      #- ./fastapi-service/app:/opt/shared-code/app

  frontend:
    build: ./frontend
    container_name: weather-frontend
    #ports:
    #  - "3000:3000"
    depends_on:
      - backend
    volumes:
      - ./frontend:/app

  caddy:
    image: caddy:2.7
    container_name: caddy
    restart: unless-stopped
    ports:
      - "80:80"      # HTTP (für ACME + Redirect)
      - "443:443"    # HTTPS (öffentlich)
    volumes:
      - ./caddy/Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
      - caddy_config:/config
    env_file:
      - .env
    depends_on:
      - frontend
      - backend
      - airflow-webserver 
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 300M 

volumes:
  postgres_data:
  airflow_postgres_data:
  caddy_data:
  caddy_config: